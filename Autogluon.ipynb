{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from glob import glob\n",
    "from tqdm import tqdm\n",
    "import pickle\n",
    "from sklearn.model_selection import train_test_split\n",
    "from autogluon.tabular import TabularDataset, TabularPredictor\n",
    "\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Leer los datos\n",
    "train_split = pd.read_csv('./train_split.csv')\n",
    "with open('./X.pkl', 'rb') as f:\n",
    "    X = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aplanar y normalizar las im치genes\n",
    "X = X.reshape(X.shape[0], -1)\n",
    "max_val = X.max()\n",
    "X = X / max_val\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear dataframe\n",
    "df = pd.DataFrame(X)\n",
    "df['class'] = train_split['class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Crear sets de entrenamiento y validaci칩n\n",
    "train_data, test_data = train_test_split(df, test_size=0.2, random_state=42, stratify=df['class'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No path specified. Models will be saved in: \"AutogluonModels\\ag-20231116_163322\\\"\n",
      "Beginning AutoGluon training ... Time limit = 3600s\n",
      "AutoGluon will save models to \"AutogluonModels\\ag-20231116_163322\\\"\n",
      "AutoGluon Version:  0.8.2\n",
      "Python Version:     3.10.11\n",
      "Operating System:   Windows\n",
      "Platform Machine:   AMD64\n",
      "Platform Version:   10.0.22631\n",
      "Disk Space Avail:   287.91 GB / 998.60 GB (28.8%)\n",
      "Train Data Rows:    2400\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Data Columns: 150528\n",
      "Label Column: class\n",
      "Preprocessing data ...\n",
      "AutoGluon infers your prediction problem is: 'multiclass' (because dtype of label-column == object).\n",
      "\t3 unique label values:  ['challenge', 'play', 'throwin']\n",
      "\tIf 'multiclass' is not the correct problem_type, please manually specify the problem_type parameter during predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\n",
      "Train Data Class Count: 3\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    5634.24 MB\n",
      "\tTrain Data (Original)  Memory Usage: 1445.07 MB (25.6% of available memory)\n",
      "\tWarning: Data size prior to feature transformation consumes 25.6% of available memory. Consider increasing memory or subsampling the data to avoid instability.\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\t\t\tNote: Converting 590 features to boolean dtype as they only contain 2 unique values.\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tUseless Original Features (Count: 2109): ['11850', '11851', '11852', '11853', '11854', '11856', '11857', '11859', '11860', '11862', '11863', '11864', '11865', '11866', '11868', '11869', '11871', '11872', '11873', '11874', '11875', '11876', '11877', '11878', '11880', '11881', '11882', '11883', '11884', '11885', '11886', '11887', '11889', '11890', '11892', '11893', '11895', '11896', '11897', '11898', '11899', '11901', '11902', '11903', '11904', '11905', '11906', '11907', '11908', '11910', '11911', '11912', '11913', '11914', '11915', '11916', '11917', '11918', '11919', '11920', '11921', '11922', '11923', '11925', '11926', '11928', '11929', '11931', '11932', '11933', '11934', '11935', '11936', '11937', '11938', '11940', '11941', '11942', '11943', '11944', '11945', '11946', '11947', '11948', '11949', '11950', '11951', '11952', '11953', '11954', '11955', '11956', '11957', '11958', '11959', '11960', '11961', '11962', '11963', '11964', '11965', '11966', '11967', '11968', '11969', '11970', '11971', '11972', '11973', '11974', '11975', '11976', '11977', '11978', '11979', '11980', '11981', '11982', '11983', '11984', '11985', '11986', '11987', '11988', '11989', '11990', '11991', '11992', '11993', '11994', '11995', '11996', '11997', '11998', '11999', '12003', '12004', '12006', '12007', '12009', '12010', '12012', '12013', '12014', '12018', '12019', '12020', '12021', '12022', '12024', '12025', '12026', '12027', '12028', '12030', '12031', '12033', '12034', '12036', '12037', '12039', '12040', '12042', '12043', '12045', '12046', '12048', '12049', '12051', '12052', '12054', '12055', '12063', '12064', '12519', '12520', '12522', '12523', '12524', '12525', '12526', '12528', '12529', '12531', '12532', '12534', '12535', '12536', '12537', '12538', '12540', '12541', '12542', '12543', '12544', '12545', '12546', '12547', '12548', '12549', '12550', '12551', '12552', '12553', '12554', '12555', '12556', '12557', '12558', '12559', '12561', '12562', '12563', '12564', '12565', '12566', '12567', '12568', '12569', '12570', '12571', '12572', '12573', '12574', '12575', '12576', '12577', '12578', '12579', '12580', '12582', '12583', '12584', '12585', '12586', '12587', '12588', '12589', '12590', '12591', '12592', '12593', '12594', '12595', '12596', '12597', '12598', '12599', '12600', '12601', '12602', '12603', '12604', '12605', '12606', '12607', '12608', '12609', '12610', '12612', '12613', '12614', '12615', '12616', '12617', '12618', '12619', '12620', '12621', '12622', '12623', '12624', '12625', '12626', '12627', '12628', '12629', '12630', '12631', '12632', '12633', '12634', '12635', '12636', '12637', '12638', '12639', '12640', '12641', '12642', '12643', '12644', '12645', '12646', '12647', '12648', '12649', '12650', '12651', '12652', '12653', '12654', '12655', '12656', '12657', '12658', '12659', '12660', '12661', '12662', '12663', '12664', '12665', '12666', '12667', '12668', '12669', '12670', '12671', '12672', '12673', '12675', '12676', '12677', '12678', '12679', '12681', '12682', '12683', '12684', '12685', '12686', '12687', '12688', '12690', '12691', '12692', '12693', '12694', '12696', '12697', '12698', '12699', '12700', '12702', '12703', '12705', '12706', '12708', '12709', '12710', '12714', '12715', '12717', '12718', '12719', '12720', '12721', '12722', '12723', '12724', '12726', '12727', '12729', '12730', '13191', '13194', '13195', '13196', '13197', '13198', '13200', '13201', '13203', '13204', '13206', '13207', '13208', '13209', '13210', '13215', '13216', '13217', '13218', '13219', '13220', '13221', '13222', '13223', '13224', '13225', '13226', '13227', '13228', '13229', '13230', '13231', '13233', '13234', '13239', '13240', '13241', '13242', '13243', '13244', '13245', '13246', '13248', '13249', '13250', '13251', '13252', '13253', '13254', '13255', '13256', '13257', '13258', '13259', '13260', '13261', '13262', '13263', '13264', '13265', '13266', '13267', '13268', '13269', '13270', '13271', '13272', '13273', '13275', '13276', '13278', '13279', '13280', '13281', '13282', '13283', '13284', '13285', '13286', '13287', '13288', '13289', '13290', '13291', '13292', '13293', '13294', '13295', '13296', '13297', '13298', '13299', '13300', '13301', '13302', '13303', '13304', '13305', '13306', '13308', '13309', '13311', '13312', '13313', '13314', '13315', '13316', '13317', '13318', '13323', '13324', '13326', '13327', '13328', '13329', '13330', '13331', '13335', '13336', '13338', '13339', '13340', '13341', '13342', '13343', '13347', '13348', '13350', '13351', '13359', '13360', '13362', '13363', '13364', '13365', '13366', '13367', '13368', '13369', '13370', '13371', '13372', '13374', '13375', '13377', '13378', '13380', '13381', '13383', '13384', '13385', '13386', '13387', '13389', '13390', '13391', '13392', '13393', '13401', '13402', '13863', '13864', '13866', '13867', '13869', '13870', '13872', '13873', '13874', '13875', '13876', '13877', '13878', '13879', '13880', '13881', '13882', '13884', '13885', '13886', '13887', '13888', '13890', '13891', '13892', '13893', '13894', '13896', '13897', '13898', '13899', '13900', '13902', '13903', '13904', '13905', '13906', '13907', '13908', '13909', '13910', '13911', '13912', '13914', '13915', '13916', '13917', '13918', '13920', '13921', '13923', '13924', '13925', '13926', '13927', '13928', '13929', '13930', '13931', '13932', '13933', '13934', '13935', '13936', '13937', '13938', '13939', '13940', '13941', '13942', '13943', '13944', '13945', '13946', '13947', '13948', '13949', '13950', '13951', '13952', '13953', '13954', '13955', '13956', '13957', '13958', '13959', '13960', '13961', '13962', '13963', '13964', '13965', '13966', '13967', '13968', '13969', '13970', '13971', '13972', '13974', '13975', '13977', '13978', '13979', '13980', '13981', '13982', '13983', '13984', '13985', '13986', '13987', '13988', '13989', '13990', '13991', '13992', '13993', '13994', '13995', '13996', '13997', '13998', '13999', '14001', '14002', '14003', '14004', '14005', '14006', '14007', '14008', '14010', '14011', '14013', '14014', '14015', '14016', '14017', '14018', '14019', '14020', '14021', '14022', '14023', '14025', '14026', '14037', '14038', '14039', '14043', '14044', '14046', '14047', '14055', '14056', '14058', '14059', '14060', '14061', '14062', '14064', '14065', '14067', '14068', '14070', '14071', '14073', '14074', '14075', '14076', '14077', '14079', '14080', '14535', '14536', '14538', '14539', '14540', '14541', '14542', '14544', '14545', '14546', '14547', '14548', '14549', '14550', '14551', '14552', '14553', '14554', '14556', '14557', '14558', '14559', '14560', '14562', '14563', '14564', '14565', '14566', '14568', '14569', '14570', '14571', '14572', '14574', '14575', '14576', '14577', '14578', '14579', '14580', '14581', '14582', '14583', '14584', '14586', '14587', '14588', '14589', '14590', '14591', '14592', '14593', '14594', '14595', '14596', '14597', '14598', '14599', '14600', '14601', '14602', '14603', '14604', '14605', '14606', '14607', '14608', '14609', '14610', '14611', '14612', '14613', '14614', '14615', '14616', '14617', '14618', '14619', '14620', '14621', '14622', '14623', '14624', '14625', '14626', '14627', '14628', '14629', '14630', '14631', '14632', '14633', '14634', '14635', '14636', '14637', '14638', '14639', '14640', '14641', '14642', '14643', '14644', '14645', '14646', '14647', '14648', '14649', '14650', '14651', '14652', '14653', '14654', '14655', '14656', '14657', '14658', '14659', '14660', '14661', '14662', '14663', '14664', '14665', '14666', '14667', '14668', '14669', '14670', '14671', '14673', '14674', '14675', '14676', '14677', '14678', '14679', '14680', '14682', '14683', '14684', '14685', '14686', '14687', '14688', '14689', '14690', '14691', '14692', '14693', '14694', '14695', '14697', '14698', '14703', '14704', '14709', '14710', '14711', '14715', '14716', '14718', '14719', '14727', '14728', '14730', '14731', '14732', '14733', '14734', '14736', '14737', '14738', '14739', '14740', '14742', '14743', '14745', '14746', '14748', '14749', '14751', '14752', '15207', '15208', '15210', '15211', '15212', '15213', '15214', '15216', '15217', '15218', '15219', '15220', '15221', '15222', '15223', '15224', '15225', '15226', '15228', '15229', '15230', '15231', '15232', '15234', '15235', '15236', '15237', '15238', '15240', '15241', '15242', '15243', '15244', '15246', '15247', '15248', '15249', '15250', '15251', '15252', '15253', '15255', '15256', '15258', '15259', '15260', '15261', '15262', '15263', '15264', '15265', '15266', '15267', '15268', '15269', '15270', '15271', '15272', '15273', '15274', '15275', '15276', '15277', '15278', '15279', '15280', '15281', '15282', '15283', '15284', '15285', '15286', '15287', '15288', '15289', '15290', '15291', '15292', '15293', '15294', '15295', '15296', '15297', '15298', '15299', '15300', '15301', '15302', '15303', '15304', '15305', '15306', '15307', '15308', '15309', '15310', '15311', '15312', '15313', '15314', '15315', '15316', '15318', '15319', '15320', '15321', '15322', '15323', '15324', '15325', '15326', '15327', '15328', '15329', '15330', '15331', '15332', '15333', '15334', '15336', '15337', '15339', '15340', '15341', '15342', '15343', '15345', '15346', '15347', '15348', '15349', '15354', '15355', '15356', '15357', '15358', '15359', '15360', '15361', '15362', '15363', '15364', '15365', '15366', '15367', '15369', '15370', '15375', '15376', '15377', '15381', '15382', '15383', '15387', '15388', '15390', '15391', '15399', '15400', '15402', '15403', '15405', '15406', '15408', '15409', '15410', '15411', '15412', '15414', '15415', '15417', '15418', '15420', '15421', '15423', '15424', '15877', '15879', '15880', '15882', '15883', '15885', '15886', '15887', '15888', '15889', '15891', '15892', '15894', '15895', '15896', '15897', '15898', '15899', '15900', '15901', '15902', '15903', '15904', '15906', '15907', '15908', '15909', '15910', '15911', '15912', '15913', '15914', '15915', '15916', '15917', '15918', '15919', '15920', '15921', '15922', '15924', '15925', '15926', '15927', '15928', '15929', '15930', '15931', '15932', '15933', '15934', '15935', '15936', '15937', '15938', '15939', '15940', '15941', '15942', '15943', '15944', '15945', '15946', '15947', '15948', '15949', '15950', '15951', '15952', '15953', '15954', '15955', '15956', '15957', '15958', '15959', '15960', '15961', '15962', '15963', '15964', '15965', '15966', '15967', '15968', '15969', '15970', '15971', '15972', '15973', '15975', '15976', '15977', '15978', '15979', '15980', '15981', '15982', '15983', '15984', '15985', '15986', '15987', '15988', '15990', '15991', '15993', '15994', '15996', '15997', '15999', '16000', '16002', '16003', '16004', '16005', '16006', '16008', '16009', '16010', '16011', '16012', '16013', '16014', '16015', '16016', '16017', '16018', '16020', '16021', '16023', '16024', '16029', '16030', '16032', '16033', '16035', '16036', '16038', '16039', '16040', '16041', '16042', '16044', '16045', '16047', '16048', '16049', '16050', '16051', '16052', '16053', '16054', '16056', '16057', '16059', '16060', '16065', '16066', '16074', '16075', '16080', '16081', '16083', '16084', '16086', '16087', '16095', '16096', '16548', '16549', '16551', '16552', '16554', '16555', '16557', '16558', '16559', '16560', '16561', '16563', '16564', '16566', '16567', '16568', '16569', '16570', '16571', '16572', '16573', '16574', '16575', '16576', '16578', '16579', '16580', '16581', '16582', '16583', '16584', '16585', '16586', '16587', '16588', '16589', '16590', '16591', '16592', '16593', '16594', '16596', '16597', '16598', '16599', '16600', '16601', '16602', '16603', '16604', '16605', '16606', '16607', '16608', '16609', '16610', '16611', '16612', '16613', '16614', '16615', '16616', '16617', '16618', '16619', '16620', '16621', '16622', '16623', '16624', '16625', '16626', '16627', '16628', '16629', '16630', '16631', '16632', '16633', '16635', '16636', '16637', '16638', '16639', '16640', '16641', '16642', '16643', '16644', '16645', '16647', '16648', '16649', '16650', '16651', '16652', '16653', '16654', '16655', '16656', '16657', '16658', '16659', '16660', '16662', '16663', '16664', '16665', '16666', '16668', '16669', '16671', '16672', '16674', '16675', '16676', '16677', '16678', '16679', '16680', '16681', '16682', '16683', '16684', '16685', '16686', '16687', '16688', '16689', '16690', '16692', '16693', '16695', '16696', '16698', '16699', '16700', '16701', '16702', '16703', '16704', '16705', '16707', '16708', '16710', '16711', '16712', '16713', '16714', '16716', '16717', '16718', '16719', '16720', '16721', '16722', '16723', '16724', '16725', '16726', '16728', '16729', '16731', '16732', '16737', '16738', '16740', '16741', '16746', '16747', '16752', '16753', '16754', '16755', '16756', '16758', '16759', '16761', '16762', '16763', '16764', '16765', '16767', '16768', '17223', '17224', '17226', '17227', '17228', '17229', '17230', '17231', '17232', '17233', '17235', '17236', '17238', '17239', '17240', '17241', '17242', '17243', '17244', '17245', '17246', '17247', '17248', '17250', '17251', '17252', '17253', '17254', '17255', '17256', '17257', '17258', '17259', '17260', '17261', '17262', '17263', '17264', '17265', '17266', '17268', '17269', '17270', '17271', '17272', '17273', '17274', '17275', '17276', '17277', '17278', '17279', '17280', '17281', '17282', '17283', '17284', '17285', '17286', '17287', '17288', '17289', '17290', '17291', '17292', '17293', '17294', '17295', '17296', '17297', '17298', '17299', '17300', '17301', '17302', '17303', '17304', '17305', '17307', '17308', '17310', '17311', '17312', '17313', '17314', '17315', '17316', '17317', '17319', '17320', '17321', '17322', '17323', '17324', '17325', '17326', '17327', '17328', '17329', '17330', '17331', '17332', '17334', '17335', '17336', '17337', '17338', '17339', '17340', '17341', '17346', '17347', '17348', '17349', '17350', '17351', '17352', '17353', '17355', '17356', '17357', '17358', '17359', '17360', '17361', '17362', '17364', '17365', '17367', '17368', '17370', '17371', '17372', '17373', '17374', '17375', '17376', '17377', '17379', '17380', '17382', '17383', '17385', '17386', '17388', '17389', '17390', '17391', '17392', '17393', '17394', '17395', '17396', '17397', '17398', '17400', '17401', '17403', '17404', '17409', '17410', '17412', '17413', '17427', '17428', '17430', '17431', '17433', '17434', '17435', '17436', '17437', '17439', '17440', '17895', '17898', '17899', '17900', '17901', '17902', '17903', '17904', '17905', '17907', '17908', '17910', '17911', '17916', '17917', '17918', '17919', '17920', '17922', '17923', '17925', '17926', '17927', '17928', '17929', '17930', '17931', '17932', '17933', '17934', '17935', '17936', '17937', '17938', '17940', '17941', '17943', '17944', '17946', '17947', '17949', '17950', '17951', '17952', '17953', '17954', '17955', '17956', '17957', '17958', '17959', '17960', '17961', '17962', '17963', '17964', '17965', '17967', '17968', '17970', '17971', '17972', '17973', '17974', '17975', '17976', '17977', '17978', '17979', '17980', '17982', '17983', '17985', '17986', '17988', '17989', '17991', '17992', '17993', '17994', '17995', '17996', '17997', '17998', '18000', '18001', '18003', '18004', '18006', '18007', '18008', '18009', '18010', '18011', '18012', '18013', '18018', '18019', '18020', '18021', '18022', '18027', '18028', '18029', '18030', '18031', '18032', '18033', '18034', '18036', '18037', '18039', '18040', '18042', '18043', '18044', '18045', '18046', '18047', '18048', '18049', '18051', '18052', '18054', '18055', '18057', '18058', '18060', '18061', '18063', '18064', '18066', '18067', '18068', '18072', '18073', '18075', '18076', '18084', '18085', '18090', '18091', '18096', '18097', '18099', '18100', '18105', '18106', '18111', '18112', '18565', '18567', '18568', '18570', '18571', '18572', '18573', '18574', '18575', '18576', '18577', '18579', '18580', '18581', '18582', '18583', '18585', '18586', '18587', '18588', '18589', '18590', '18591', '18592', '18593', '18594', '18595', '18597', '18598', '18599', '18600', '18601', '18602', '18603', '18604', '18606', '18607', '18608', '18609', '18610', '18611', '18612', '18613', '18614', '18615', '18616', '18617', '18618', '18619', '18620', '18621', '18622', '18623', '18624', '18625', '18626', '18627', '18628', '18629', '18630', '18631', '18632', '18633', '18634', '18635', '18636', '18637', '18638', '18639', '18640', '18641', '18642', '18643', '18644', '18645', '18646', '18648', '18649', '18650', '18651', '18652', '18653', '18654', '18655', '18656', '18657', '18658', '18659', '18660', '18661', '18662', '18663', '18664', '18665', '18666', '18667', '18668', '18669', '18670', '18671', '18672', '18673', '18674', '18675', '18676', '18677', '18678', '18679', '18680', '18681', '18682', '18683', '18684', '18685', '18686', '18687', '18688', '18689', '18690', '18691', '18692', '18693', '18694', '18695', '18696', '18697', '18698', '18699', '18700', '18701', '18702', '18703', '18704', '18705', '18706', '18707', '18708', '18709', '18711', '18712', '18713', '18714', '18715', '18716', '18717', '18718', '18719', '18720', '18721', '18722', '18723', '18724', '18725', '18726', '18727', '18729', '18730', '18731', '18732', '18733', '18734', '18735', '18736', '18737', '18738', '18739', '18740', '18741', '18742', '18744', '18745', '18747', '18750', '18751', '18753', '18754', '18755', '18759', '18760', '18762', '18763', '18764', '18768', '18769', '18770', '18771', '18772', '18774', '18775', '18777', '18778', '18780', '18781', '18783', '18784', '19239', '19240', '19242', '19243', '19244', '19245', '19246', '19247', '19251', '19252', '19253', '19257', '19258', '19259', '19260', '19261', '19262', '19266', '19267', '19268', '19269', '19270', '19271', '19272', '19273', '19274', '19275', '19276', '19278', '19279', '19280', '19281', '19282', '19283', '19284', '19285', '19286', '19287', '19288', '19290', '19291', '19293', '19294', '19295', '19296', '19297', '19298', '19299', '19300', '19301', '19302', '19303', '19305', '19306', '19307', '19308', '19309', '19311', '19312', '19313', '19314', '19315', '19317', '19318', '19319', '19320', '19321', '19322', '19323', '19324', '19325', '19326', '19327', '19328', '19329', '19330', '19331', '19332', '19333', '19334', '19335', '19336', '19337', '19338', '19339', '19340', '19341', '19342', '19343', '19344', '19345', '19346', '19347', '19348', '19349', '19350', '19351', '19352', '19353', '19354', '19355', '19356', '19357', '19358', '19359', '19360', '19361', '19365', '19366', '19367', '19368', '19369', '19370', '19371', '19372', '19373', '19374', '19375', '19376', '19377', '19378', '19379', '19380', '19381', '19383', '19384', '19385', '19389', '19390', '19391', '19392', '19393', '19394', '19395', '19396', '19397', '19398', '19399', '19401', '19402', '19403', '19404', '19405', '19406', '19407', '19408', '19409', '19410', '19411', '19412', '19413', '19414', '19416', '19417', '19419', '19420', '19422', '19423', '19425', '19426', '19427', '19431', '19432', '19434', '19435', '19436', '19437', '19438', '19440', '19441', '19443', '19444', '19446', '19447', '19449', '19450', '19452', '19453']\n",
      "\t\tThese features carry no predictive signal and should be manually investigated.\n",
      "\t\tThis is typically a feature which has the same value for all rows.\n",
      "\t\tThese features do not need to be present at inference time.\n",
      "\tUnused Original Features (Count: 325): ['11845', '11848', '11858', '11867', '11879', '11909', '11930', '11939', '12000', '12001', '12015', '12016', '12017', '12023', '12058', '12061', '12517', '12527', '12533', '12539', '12560', '12581', '12611', '12674', '12680', '12695', '12701', '12711', '12712', '12713', '12716', '12728', '12733', '12736', '13189', '13199', '13205', '13211', '13213', '13214', '13232', '13235', '13237', '13274', '13277', '13310', '13320', '13321', '13332', '13333', '13334', '13337', '13344', '13345', '13349', '13352', '13353', '13354', '13355', '13356', '13357', '13358', '13361', '13373', '13376', '13382', '13396', '13398', '13399', '13404', '13405', '13408', '13913', '13922', '13976', '14009', '14028', '14029', '14030', '14032', '14035', '14040', '14041', '14049', '14050', '14052', '14053', '14537', '14543', '14555', '14561', '14567', '14573', '14585', '14672', '14681', '14696', '14699', '14700', '14701', '14702', '14706', '14707', '14712', '14713', '14714', '14720', '14721', '14722', '14724', '14725', '14726', '14729', '14735', '14741', '14744', '14747', '14750', '15209', '15215', '15227', '15239', '15245', '15335', '15338', '15344', '15350', '15351', '15352', '15353', '15368', '15371', '15372', '15373', '15374', '15378', '15379', '15380', '15384', '15385', '15386', '15389', '15392', '15393', '15394', '15396', '15397', '15407', '15413', '15416', '15419', '15923', '15995', '16007', '16027', '16028', '16031', '16043', '16046', '16063', '16068', '16069', '16072', '16076', '16077', '16078', '16090', '16092', '16093', '16099', '16553', '16562', '16565', '16577', '16634', '16646', '16667', '16670', '16673', '16691', '16694', '16697', '16706', '16709', '16715', '16727', '16730', '16733', '16734', '16735', '16736', '16739', '16743', '16744', '16745', '16748', '16749', '16750', '16751', '16760', '16771', '17221', '17225', '17237', '17249', '17267', '17306', '17318', '17333', '17342', '17344', '17345', '17354', '17363', '17366', '17369', '17378', '17387', '17399', '17402', '17405', '17406', '17407', '17408', '17411', '17414', '17415', '17416', '17417', '17419', '17421', '17422', '17423', '17424', '17425', '17443', '17897', '17906', '17909', '17912', '17914', '17921', '17924', '17942', '17945', '17948', '17966', '17969', '17981', '17984', '17987', '17990', '18002', '18005', '18014', '18015', '18016', '18017', '18023', '18024', '18025', '18041', '18065', '18070', '18078', '18079', '18082', '18086', '18087', '18088', '18093', '18094', '18103', '18108', '18109', '18113', '18115', '18564', '18605', '18749', '18757', '18766', '18779', '18782', '19237', '19249', '19250', '19255', '19264', '19265', '19277', '19292', '19363', '19364', '19382', '19387', '19388', '19400', '19415', '19418', '19424', '19428', '19429', '19433', '19451', '19454', '19456', '19921', '19924', '19975', '19978', '20020', '20044', '20047', '20050', '20053', '20059', '20062', '20071', '20074', '20104', '20107', '20116', '20119', '20128']\n",
      "\t\tThese features were not used to generate any of the output features. Add a feature generator compatible with these features to utilize them.\n",
      "\t\tFeatures can also be unused if they carry very little information, such as being categorical but having almost entirely unique values or being duplicates of other features.\n",
      "\t\tThese features do not need to be present at inference time.\n",
      "\t\t('float', []) : 325 | ['11845', '11848', '11858', '11867', '11879', ...]\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 148094 | ['0', '1', '2', '3', '4', ...]\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', [])     : 147819 | ['0', '1', '2', '3', '4', ...]\n",
      "\t\t('int', ['bool']) :    275 | ['11844', '11847', '11855', '11861', '11870', ...]\n",
      "\t6849.3s = Fit runtime\n",
      "\t148094 features in original data used to generate 148094 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 1419.72 MB (8.9% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 7038.88s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'accuracy'\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Automatically generating train/validation split with holdout_frac=0.2, Train Rows: 1920, Val Rows: 480\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'NN_TORCH': {},\n",
      "\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, 'GBMLarge'],\n",
      "\t'CAT': {},\n",
      "\t'XGB': {},\n",
      "\t'FASTAI': {},\n",
      "\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'KNN': [{'weights': 'uniform', 'ag_args': {'name_suffix': 'Unif'}}, {'weights': 'distance', 'ag_args': {'name_suffix': 'Dist'}}],\n",
      "}\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "Not enough time left to train models. Consider specifying a larger time_limit. Time remaining: -3438.88s",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\juanc\\Desktop\\UVG\\Clases\\Data_Science\\Proyecto-Data-Science\\Autogluon.ipynb Cell 6\u001b[0m line \u001b[0;36m2\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/juanc/Desktop/UVG/Clases/Data_Science/Proyecto-Data-Science/Autogluon.ipynb#W5sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m# Entrenar el modelo con AutoGluon\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/juanc/Desktop/UVG/Clases/Data_Science/Proyecto-Data-Science/Autogluon.ipynb#W5sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m predictor \u001b[39m=\u001b[39m TabularPredictor(label\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mclass\u001b[39;49m\u001b[39m'\u001b[39;49m)\u001b[39m.\u001b[39;49mfit(train_data, time_limit\u001b[39m=\u001b[39;49m\u001b[39m3600\u001b[39;49m)\n",
      "File \u001b[1;32mc:\\Users\\juanc\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\autogluon\\core\\utils\\decorators.py:31\u001b[0m, in \u001b[0;36munpack.<locals>._unpack_inner.<locals>._call\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     28\u001b[0m \u001b[39m@functools\u001b[39m\u001b[39m.\u001b[39mwraps(f)\n\u001b[0;32m     29\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_call\u001b[39m(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m     30\u001b[0m     gargs, gkwargs \u001b[39m=\u001b[39m g(\u001b[39m*\u001b[39mother_args, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m---> 31\u001b[0m     \u001b[39mreturn\u001b[39;00m f(\u001b[39m*\u001b[39mgargs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mgkwargs)\n",
      "File \u001b[1;32mc:\\Users\\juanc\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\autogluon\\tabular\\predictor\\predictor.py:986\u001b[0m, in \u001b[0;36mTabularPredictor.fit\u001b[1;34m(self, train_data, tuning_data, time_limit, presets, hyperparameters, feature_metadata, infer_limit, infer_limit_batch_size, fit_weighted_ensemble, calibrate_decision_threshold, num_cpus, num_gpus, **kwargs)\u001b[0m\n\u001b[0;32m    984\u001b[0m     aux_kwargs[\u001b[39m\"\u001b[39m\u001b[39mfit_weighted_ensemble\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[0;32m    985\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msave(silent\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)  \u001b[39m# Save predictor to disk to enable prediction and training after interrupt\u001b[39;00m\n\u001b[1;32m--> 986\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_learner\u001b[39m.\u001b[39;49mfit(\n\u001b[0;32m    987\u001b[0m     X\u001b[39m=\u001b[39;49mtrain_data,\n\u001b[0;32m    988\u001b[0m     X_val\u001b[39m=\u001b[39;49mtuning_data,\n\u001b[0;32m    989\u001b[0m     X_unlabeled\u001b[39m=\u001b[39;49munlabeled_data,\n\u001b[0;32m    990\u001b[0m     holdout_frac\u001b[39m=\u001b[39;49mholdout_frac,\n\u001b[0;32m    991\u001b[0m     num_bag_folds\u001b[39m=\u001b[39;49mnum_bag_folds,\n\u001b[0;32m    992\u001b[0m     num_bag_sets\u001b[39m=\u001b[39;49mnum_bag_sets,\n\u001b[0;32m    993\u001b[0m     num_stack_levels\u001b[39m=\u001b[39;49mnum_stack_levels,\n\u001b[0;32m    994\u001b[0m     hyperparameters\u001b[39m=\u001b[39;49mhyperparameters,\n\u001b[0;32m    995\u001b[0m     core_kwargs\u001b[39m=\u001b[39;49mcore_kwargs,\n\u001b[0;32m    996\u001b[0m     aux_kwargs\u001b[39m=\u001b[39;49maux_kwargs,\n\u001b[0;32m    997\u001b[0m     time_limit\u001b[39m=\u001b[39;49mtime_limit,\n\u001b[0;32m    998\u001b[0m     infer_limit\u001b[39m=\u001b[39;49minfer_limit,\n\u001b[0;32m    999\u001b[0m     infer_limit_batch_size\u001b[39m=\u001b[39;49minfer_limit_batch_size,\n\u001b[0;32m   1000\u001b[0m     verbosity\u001b[39m=\u001b[39;49mverbosity,\n\u001b[0;32m   1001\u001b[0m     use_bag_holdout\u001b[39m=\u001b[39;49muse_bag_holdout,\n\u001b[0;32m   1002\u001b[0m )\n\u001b[0;32m   1003\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_set_post_fit_vars()\n\u001b[0;32m   1005\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_post_fit(\n\u001b[0;32m   1006\u001b[0m     keep_only_best\u001b[39m=\u001b[39mkwargs[\u001b[39m\"\u001b[39m\u001b[39mkeep_only_best\u001b[39m\u001b[39m\"\u001b[39m],\n\u001b[0;32m   1007\u001b[0m     refit_full\u001b[39m=\u001b[39mkwargs[\u001b[39m\"\u001b[39m\u001b[39mrefit_full\u001b[39m\u001b[39m\"\u001b[39m],\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1012\u001b[0m     infer_limit\u001b[39m=\u001b[39minfer_limit,\n\u001b[0;32m   1013\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\juanc\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\autogluon\\tabular\\learner\\abstract_learner.py:159\u001b[0m, in \u001b[0;36mAbstractTabularLearner.fit\u001b[1;34m(self, X, X_val, **kwargs)\u001b[0m\n\u001b[0;32m    157\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mAssertionError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mLearner is already fit.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    158\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_validate_fit_input(X\u001b[39m=\u001b[39mX, X_val\u001b[39m=\u001b[39mX_val, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m--> 159\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_fit(X\u001b[39m=\u001b[39mX, X_val\u001b[39m=\u001b[39mX_val, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\juanc\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\autogluon\\tabular\\learner\\default_learner.py:157\u001b[0m, in \u001b[0;36mDefaultLearner._fit\u001b[1;34m(self, X, X_val, X_unlabeled, holdout_frac, num_bag_folds, num_bag_sets, time_limit, infer_limit, infer_limit_batch_size, verbosity, **trainer_fit_kwargs)\u001b[0m\n\u001b[0;32m    154\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39meval_metric \u001b[39m=\u001b[39m trainer\u001b[39m.\u001b[39meval_metric\n\u001b[0;32m    156\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msave()\n\u001b[1;32m--> 157\u001b[0m trainer\u001b[39m.\u001b[39mfit(\n\u001b[0;32m    158\u001b[0m     X\u001b[39m=\u001b[39mX,\n\u001b[0;32m    159\u001b[0m     y\u001b[39m=\u001b[39my,\n\u001b[0;32m    160\u001b[0m     X_val\u001b[39m=\u001b[39mX_val,\n\u001b[0;32m    161\u001b[0m     y_val\u001b[39m=\u001b[39my_val,\n\u001b[0;32m    162\u001b[0m     X_unlabeled\u001b[39m=\u001b[39mX_unlabeled,\n\u001b[0;32m    163\u001b[0m     holdout_frac\u001b[39m=\u001b[39mholdout_frac,\n\u001b[0;32m    164\u001b[0m     time_limit\u001b[39m=\u001b[39mtime_limit_trainer,\n\u001b[0;32m    165\u001b[0m     infer_limit\u001b[39m=\u001b[39minfer_limit,\n\u001b[0;32m    166\u001b[0m     infer_limit_batch_size\u001b[39m=\u001b[39minfer_limit_batch_size,\n\u001b[0;32m    167\u001b[0m     groups\u001b[39m=\u001b[39mgroups,\n\u001b[0;32m    168\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mtrainer_fit_kwargs,\n\u001b[0;32m    169\u001b[0m )\n\u001b[0;32m    170\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msave_trainer(trainer\u001b[39m=\u001b[39mtrainer)\n\u001b[0;32m    171\u001b[0m time_end \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime()\n",
      "File \u001b[1;32mc:\\Users\\juanc\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\autogluon\\tabular\\trainer\\auto_trainer.py:114\u001b[0m, in \u001b[0;36mAutoTrainer.fit\u001b[1;34m(self, X, y, hyperparameters, X_val, y_val, X_unlabeled, holdout_frac, num_stack_levels, core_kwargs, aux_kwargs, time_limit, infer_limit, infer_limit_batch_size, use_bag_holdout, groups, **kwargs)\u001b[0m\n\u001b[0;32m    111\u001b[0m log_str \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m}\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    112\u001b[0m logger\u001b[39m.\u001b[39mlog(\u001b[39m20\u001b[39m, log_str)\n\u001b[1;32m--> 114\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_train_multi_and_ensemble(\n\u001b[0;32m    115\u001b[0m     X\u001b[39m=\u001b[39;49mX,\n\u001b[0;32m    116\u001b[0m     y\u001b[39m=\u001b[39;49my,\n\u001b[0;32m    117\u001b[0m     X_val\u001b[39m=\u001b[39;49mX_val,\n\u001b[0;32m    118\u001b[0m     y_val\u001b[39m=\u001b[39;49my_val,\n\u001b[0;32m    119\u001b[0m     X_unlabeled\u001b[39m=\u001b[39;49mX_unlabeled,\n\u001b[0;32m    120\u001b[0m     hyperparameters\u001b[39m=\u001b[39;49mhyperparameters,\n\u001b[0;32m    121\u001b[0m     num_stack_levels\u001b[39m=\u001b[39;49mnum_stack_levels,\n\u001b[0;32m    122\u001b[0m     time_limit\u001b[39m=\u001b[39;49mtime_limit,\n\u001b[0;32m    123\u001b[0m     core_kwargs\u001b[39m=\u001b[39;49mcore_kwargs,\n\u001b[0;32m    124\u001b[0m     aux_kwargs\u001b[39m=\u001b[39;49maux_kwargs,\n\u001b[0;32m    125\u001b[0m     infer_limit\u001b[39m=\u001b[39;49minfer_limit,\n\u001b[0;32m    126\u001b[0m     infer_limit_batch_size\u001b[39m=\u001b[39;49minfer_limit_batch_size,\n\u001b[0;32m    127\u001b[0m     groups\u001b[39m=\u001b[39;49mgroups,\n\u001b[0;32m    128\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\juanc\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\autogluon\\core\\trainer\\abstract_trainer.py:2356\u001b[0m, in \u001b[0;36mAbstractTrainer._train_multi_and_ensemble\u001b[1;34m(self, X, y, X_val, y_val, hyperparameters, X_unlabeled, num_stack_levels, time_limit, groups, **kwargs)\u001b[0m\n\u001b[0;32m   2354\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Identical to self.train_multi_levels, but also saves the data to disk. This should only ever be called once.\"\"\"\u001b[39;00m\n\u001b[0;32m   2355\u001b[0m \u001b[39mif\u001b[39;00m time_limit \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m time_limit \u001b[39m<\u001b[39m\u001b[39m=\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m-> 2356\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mAssertionError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mNot enough time left to train models. Consider specifying a larger time_limit. Time remaining: \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mround\u001b[39m(time_limit,\u001b[39m \u001b[39m\u001b[39m2\u001b[39m)\u001b[39m}\u001b[39;00m\u001b[39ms\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m   2357\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msave_data \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mis_data_saved:\n\u001b[0;32m   2358\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msave_X(X)\n",
      "\u001b[1;31mAssertionError\u001b[0m: Not enough time left to train models. Consider specifying a larger time_limit. Time remaining: -3438.88s"
     ]
    }
   ],
   "source": [
    "# Entrenar el modelo con AutoGluon\n",
    "predictor = TabularPredictor(label='class').fit(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'predictor' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\juanc\\Desktop\\UVG\\Clases\\Data_Science\\Proyecto-Data-Science\\Autogluon.ipynb Cell 7\u001b[0m line \u001b[0;36m2\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/juanc/Desktop/UVG/Clases/Data_Science/Proyecto-Data-Science/Autogluon.ipynb#W6sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m# Evaluar en el conjunto de validaci칩n\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/juanc/Desktop/UVG/Clases/Data_Science/Proyecto-Data-Science/Autogluon.ipynb#W6sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m results \u001b[39m=\u001b[39m predictor\u001b[39m.\u001b[39mevaluate(test_data)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/juanc/Desktop/UVG/Clases/Data_Science/Proyecto-Data-Science/Autogluon.ipynb#W6sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mThe accuracy on the test set is of \u001b[39m\u001b[39m{\u001b[39;00mresults[\u001b[39m'\u001b[39m\u001b[39maccuracy\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m:\u001b[39;00m\u001b[39m.2f\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/juanc/Desktop/UVG/Clases/Data_Science/Proyecto-Data-Science/Autogluon.ipynb#W6sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39m# Guardar el modelo\u001b[39;00m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'predictor' is not defined"
     ]
    }
   ],
   "source": [
    "# Evaluar en el conjunto de validaci칩n\n",
    "results = predictor.evaluate(test_data)\n",
    "print(f\"The accuracy on the test set is of {results['accuracy']:.2f}\")\n",
    "# Guardar el modelo\n",
    "predictor.save('autogluon')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
